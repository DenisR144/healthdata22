{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenisR144/healthdata22/blob/main/Dataton_2022_(DR_and_T_SH).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Основные действия по основной информации**\n"
      ],
      "metadata": {
        "id": "Bv7551gn9X_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC4ntWOI5Soy",
        "outputId": "deef6ca4-ad8a-4953-dd64-9fe7a680063a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подключение основных библиотек**"
      ],
      "metadata": {
        "id": "ErkAzzVY9hND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame, Series\n",
        "import sqlite3 as db\n",
        "#import re\n",
        "!pip install pymorphy2\n",
        "import pymorphy2\n",
        "import pymystem3\n",
        "from collections import Counter\n",
        "import csv"
      ],
      "metadata": {
        "id": "aN74rgG36lpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b1cc172-fabc-46d2-e1c5-818973c3eb31"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.8/dist-packages (0.9.1)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Создание основной БД (без текстовых полей)**"
      ],
      "metadata": {
        "id": "uL_ugzmX9oUM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "cqVPZtBmidG8"
      },
      "outputs": [],
      "source": [
        "#UID;Date;Name;DOB;MKB_1;MKB_2;MKB_3;Died;Violations;ViolationsCausedDeath;Hospital;Ambulance;Home;Meddoc\n",
        "#df = pd.read_csv(\"drive/MyDrive/DataMed.csv\")\n",
        "#print(df)\n",
        "\n",
        "\n",
        "def open_csv_file(csv_file_path):\n",
        "    \"\"\"\n",
        "    Open and read data from a csv file without headers (skipping the first row)\n",
        "    :param csv_file_path: path of the csv file to process\n",
        "    :return: a list with the csv content\n",
        "    \"\"\"\n",
        "    with open(csv_file_path, 'r', encoding='utf-8') as csv_file:\n",
        "        reader = csv.reader(csv_file)\n",
        "        next(reader)\n",
        "\n",
        "        data = list()\n",
        "        for row in reader:\n",
        "            data.append(row)\n",
        "\n",
        "        return data\n",
        "\n",
        "conn = db.connect(':memory:')\n",
        "cur = conn.cursor()\n",
        "cur.execute(\"DROP TABLE IF EXISTS table1\")\n",
        "\n",
        "create_table = \"\"\"CREATE TABLE table1(\n",
        "                uid INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                date DATE NOT NULL,\n",
        "                name VARCHAR(10) NOT NULL,\n",
        "                dob DATE NOT NULL,\n",
        "                mkb1 VARCHAR(1) NOT NULL,\n",
        "                mkb2 INTEGER NOT NULL,\n",
        "                mkb3 INTEGER NOT NULL,\n",
        "                died INTEGER NOT NULL,\n",
        "                violations INTEGER NOT NULL,\n",
        "                vcd INTEGER NOT NULL,\n",
        "                hospital INTEGER NOT NULL,\n",
        "                ambulance INTEGER NOT NULL,\n",
        "                home INTEGER NOT NULL,\n",
        "                meddoc VARCHAR(50) NOT NULL,\n",
        "                perc_of_noun FLOAT64 NULL,\n",
        "                perc_of_adj FLOAT64 NULL,\n",
        "                perc_of_verb FLOAT64 NULL,\n",
        "                alcohol_num INT NULL,\n",
        "                tabacco_num INT NULL\n",
        "                );\"\"\"\n",
        " \n",
        "cur.execute(create_table)\n",
        "\n",
        "values_to_insert = open_csv_file('drive/MyDrive/DataMed.csv')\n",
        "for vv in values_to_insert:\n",
        "  insert_records = \"\"\"INSERT INTO table1(uid,date,name,dob,mkb1,mkb2,mkb3,died,violations,vcd,hospital,ambulance,home,meddoc) \n",
        "  VALUES(\n",
        "    \"\"\"+vv[0].split(';')[0]+\"\"\",\n",
        "    \"\"\"+vv[0].split(';')[1]+\"\"\",\n",
        "    '\"\"\"+vv[0].split(';')[2]+\"\"\"',\n",
        "    \"\"\"+vv[0].split(';')[3]+\"\"\",\n",
        "    '\"\"\"+vv[0].split(';')[4]+\"\"\"',\n",
        "    \"\"\"+vv[0].split(';')[5]+\"\"\",\n",
        "    \"\"\"+vv[0].split(';')[6]+\"\"\",\n",
        "    \"\"\"+vv[0].split(';')[7]+\"\"\",\n",
        "    \"\"\"+vv[0].split(';')[8]+\"\"\",\n",
        "    \"\"\"+vv[0].split(';')[9]+\"\"\",\n",
        "    \"\"\"+vv[0].split(';')[10]+\"\"\",\n",
        "    \"\"\"+vv[0].split(';')[11]+\"\"\",\n",
        "    \"\"\"+vv[0].split(';')[12]+\"\"\",\n",
        "    '\"\"\"+vv[0].split(';')[13]+\"\"\"'\n",
        "    )\n",
        "  \"\"\"\n",
        "  cur.execute(insert_records)\n",
        "  #print(insert_records)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подгрузка текстов**"
      ],
      "metadata": {
        "id": "crOv4mRZ9tg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_meddoc(filename : str): #-> perc_of_noun,perc_of_adj,perc_of_verb,alcohol_num,tabacco_num\n",
        "  myfile = open(filename,'r') \n",
        "  words = []\n",
        "\n",
        "  try:\n",
        "    filelines = myfile.readlines()\n",
        "    for line in filelines:\n",
        "      words += line.split(' ')\n",
        "\n",
        "  finally:\n",
        "    f.close()\n",
        "\n",
        "  words2 = words\n",
        "  words3 = []\n",
        "\n",
        "  # 1 - удаление специальных символов\n",
        "\n",
        "  reg = re.compile('[^a-zA-Z]')\n",
        "  n = 0\n",
        "  for val in words2:\n",
        "    val = val.replace(\" \",\"\")\n",
        "    val = val.replace(\".\",\"\")\n",
        "    val = val.replace(\",\",\"\")\n",
        "    val = val.replace(\":\",\"\")\n",
        "    val = val.replace(\";\",\"\")\n",
        "    val = val.replace(\"1\",\"\")\n",
        "    val = val.replace(\"2\",\"\")\n",
        "    val = val.replace(\"3\",\"\")\n",
        "    val = val.replace(\"4\",\"\")\n",
        "    val = val.replace(\"5\",\"\")\n",
        "    val = val.replace(\"6\",\"\")\n",
        "    val = val.replace(\"7\",\"\")\n",
        "    val = val.replace(\"8\",\"\")\n",
        "    val = val.replace(\"9\",\"\")\n",
        "    val = val.replace(\"0\",\"\")\n",
        "    val = val.replace(\"(\",\"\")\n",
        "    val = val.replace(\")\",\"\")\n",
        "    if len(val)>1: #отсекаем пустые сроки, и односимвольные\n",
        "      words3.append(val)\n",
        "\n",
        "  print(\"Strings are affected\")\n",
        "\n",
        "\n",
        "\n",
        "  # Лемматизация\n",
        "  # Рабочий массив данных - список words3\n",
        "\n",
        "  words5 = words3\n",
        "  words6 = []\n",
        "  words_pos = []\n",
        "\n",
        "  m1 = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "  n=0\n",
        "  for val in words5:\n",
        "    p = m1.parse(val)[0]\n",
        "    words6.append(p.normal_form)\n",
        "    words_pos.append(p.tag.POS)\n",
        "    n+=1\n",
        "\n",
        "  print(str(n) + \" words affected!\")\n",
        "\n",
        "\n",
        "  # считаем количество слов по частям речи\n",
        "\n",
        "  c = Counter(words_pos)\n",
        "  \n",
        "  perc_of_noun = c['NOUN'] / len(words_pos) # доля существительных\n",
        "  perc_of_adj = c['ADJF'] / len(words_pos) # доля прилагательных\n",
        "  perc_of_verb = c['VERB'] / len(words_pos) # доля глаголов\n",
        "\n",
        "  # считаем количество слов по гипотезам (табак, алкоголь)\n",
        "\n",
        "  c2 = Counter(words6)\n",
        "  alcohol_num = c2['спирт'] + c2['выпивка'] + c2['алкоголь'] + c2['выпивать'] + c2['выпить'] + c2['пить'] + c2['водка'] + c2['пиво'] + c2['употреблять']\n",
        "  tabacco_num = c2['табак'] + c2['сигарета'] + c2['курить'] + c2['выкуривать']\n",
        "\n",
        "  return(perc_of_noun,perc_of_adj,perc_of_verb,alcohol_num,tabacco_num)\n",
        "\n"
      ],
      "metadata": {
        "id": "PqrsLS7e9wP0"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Обработка текстов**\n",
        "\n",
        "1) Стемминг (отрезаем в словах окончания и суффиксы), есть вроде готовые библиотеки под русский язык //минусы - теряем часть информации, а часть - сливается\n",
        "\n",
        "*или* \n",
        "\n",
        "2) Лемматизация (морфологический анализ) с целью логического объединения разных форм (например \"шёл\", \"идти\" - перевод в слов в начальные формы) - библиотеки pymorphy2, pymystem3\n",
        "\n",
        "3) частотный анализ, т.е. закидываем все слова с частотным анализом в матрицу, и дальше обрабатываем как вектора\n",
        "Это надо делать после выше приведенных 1 или 2\n",
        "\n",
        "4) составление матрицы по частоте использования частей речи (глагол, существительное, прилагательное), перевод их в процентное соотношение от объема текста"
      ],
      "metadata": {
        "id": "25t33QEj9ws6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. избавимся от всех лишних символов, кроме русских букв, дефисов и пробелов.\n",
        "\n",
        "\n",
        "2. цепочка дат событий: приведение дат к единому формату, выстраивание цепочек\n",
        "\n",
        "3. создание словаря - значимых терминов (от Дениса Рощина, максимальная вероятность получить нормальный словарь)\n",
        "далее слова из этого словаря найти в текстах и по каждой истории болезни вывести частотную характеристику по каждому слову словаря\n",
        "В словаре могут быть синонимы.\n",
        "Статистику по синонимам объединить.\n",
        "\n",
        "Со словарем значимых слов мне кажется будет решение изящнее..."
      ],
      "metadata": {
        "id": "HPokM_3TBTVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "res = cur.execute(\"SELECT uid,meddoc FROM table1\")\n",
        "row = res.fetchall()\n",
        "row\n",
        "\n",
        "for a in row:\n",
        "  aa = parse_meddoc(a[1]) #perc_of_noun,perc_of_adj,perc_of_verb,alcohol_num,tabacco_num\n",
        "  res2 = cur.execute(\"UPDATE table1 SET perc_of_noun = '\"+str(aa[0])+\"', perc_of_adj = '\"+str(aa[1])+\"',perc_of_verb = '\"+str(aa[2])+\"',alcohol_num = '\"+str(aa[3])+\"',tabacco_num = '\"+str(aa[4])+\"' WHERE UID=\"+str(a[0]))\n",
        "\n",
        "res = cur.execute(\"SELECT * FROM table1\")\n",
        "row = res.fetchall()\n",
        "row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8yX2KiQwtYL",
        "outputId": "5ec96f99-a652-4a0f-c9f6-890cfc0b486a"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strings are affected\n",
            "31723 words affected!\n",
            "Strings are affected\n",
            "50871 words affected!\n",
            "Strings are affected\n",
            "26670 words affected!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1,\n",
              "  2004,\n",
              "  'GGT',\n",
              "  1993,\n",
              "  'C',\n",
              "  61,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  '1.txt',\n",
              "  0.5193392806481102,\n",
              "  0.21375658039907952,\n",
              "  0.03574693440090786,\n",
              "  0,\n",
              "  0),\n",
              " (2,\n",
              "  1999,\n",
              "  'ATM',\n",
              "  1991,\n",
              "  'О',\n",
              "  26,\n",
              "  8,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  '2.txt',\n",
              "  0.49448605295748066,\n",
              "  0.19567140413988324,\n",
              "  0.04680466277446876,\n",
              "  5,\n",
              "  0),\n",
              " (3,\n",
              "  2008,\n",
              "  'CAM',\n",
              "  1914,\n",
              "  'I',\n",
              "  63,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  '3.txt',\n",
              "  0.4752530933633296,\n",
              "  0.2116610423697038,\n",
              "  0.03880764904386952,\n",
              "  0,\n",
              "  0)]"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = cur.execute(\"PRAGMA table_info(table1);\")\n",
        "row = res.fetchall()\n",
        "\n",
        "\n",
        "row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqj_JhYZ2Kra",
        "outputId": "e66c6241-407b-48e5-f0eb-201c1ce96a49"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'uid', 'INTEGER', 0, None, 1),\n",
              " (1, 'date', 'DATE', 1, None, 0),\n",
              " (2, 'name', 'VARCHAR(10)', 1, None, 0),\n",
              " (3, 'dob', 'DATE', 1, None, 0),\n",
              " (4, 'mkb1', 'VARCHAR(1)', 1, None, 0),\n",
              " (5, 'mkb2', 'INTEGER', 1, None, 0),\n",
              " (6, 'mkb3', 'INTEGER', 1, None, 0),\n",
              " (7, 'died', 'INTEGER', 1, None, 0),\n",
              " (8, 'violations', 'INTEGER', 1, None, 0),\n",
              " (9, 'vcd', 'INTEGER', 1, None, 0),\n",
              " (10, 'hospital', 'INTEGER', 1, None, 0),\n",
              " (11, 'ambulance', 'INTEGER', 1, None, 0),\n",
              " (12, 'home', 'INTEGER', 1, None, 0),\n",
              " (13, 'meddoc', 'VARCHAR(50)', 1, None, 0),\n",
              " (14, 'perc_of_noun', 'FLOAT64', 0, None, 0),\n",
              " (15, 'perc_of_adj', 'FLOAT64', 0, None, 0),\n",
              " (16, 'perc_of_verb', 'FLOAT64', 0, None, 0),\n",
              " (17, 'alcohol_num', 'INT', 0, None, 0),\n",
              " (18, 'tabacco_num', 'INT', 0, None, 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Основной анализ обработанного текста и основных полей**"
      ],
      "metadata": {
        "id": "Qg8JlyeQ9zGu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_B4iAhw93i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Всяческая визуализация**"
      ],
      "metadata": {
        "id": "OsuPcaFU93Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z-BJq1Kh95FF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}